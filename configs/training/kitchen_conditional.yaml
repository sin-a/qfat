defaults:
  - /entrypoints/TrainingEntrypointCfg@_here_
  - /wandb/WandbCfg@wandb_cfg
  - /datasets/SlicedTrajectoryDatasetCfg@slicer_cfg
  - /models/QFATCfg@model_cfg
  - /optimizers/OptimizerCfg@model_cfg.optimizer_cfg
  - /models/IdentityEncoderCfg@model_cfg.encoder_cfg
  - /models/DecoderBlockCfg@model_cfg.decoder_block_cfg
  - /models/MultiheadAttentionCfg@model_cfg.decoder_block_cfg.mha_cfg
  - /datasets/KitchenTrajectoryDatasetCfg@training_dataset_cfg
  - /dataloaders/DataLoaderCfg@train_dataloader_cfg
  - _self_
wandb_cfg:
  name: ${model_cfg.mixture_size}mix
  group: kitchen_conditional
  project: qfat
  id:  # set id here to resume training from a checkpoint 
  notes:
  mode: online
training_dataset_cfg:
  include_goals: true
train_dataloader_cfg:
  shuffle: true
  batch_size: 128
  num_workers: 0
  persistent_workers: false
val_dataloader_cfg:
  shuffle: false
  batch_size: 1024
  num_workers: 4
model_cfg:
  sample_fn: gmm
  full_covariance: false
  n_layer: 6
  embd_dropout: 0 
  context_len: 10 
  input_dim: 30
  conditional_seq_dim: ${model_cfg.input_dim}
  share_state_encoder: true 
  share_projection_layer: true
  out_dim: 9 # action_dim*(action_horizon + 1)
  mixture_size: 4
  optimizer_cfg:
    n_epochs: 1001 
    use_cosine_schedule: false
    learning_rate: 0.001
  decoder_block_cfg:
    residual_dropout: 0.1
    mha_cfg:
      embed_dim: 128
      num_heads: 8
      dropout: 0.1
  lambda_mixtures: 0
slicer_cfg:
  window: ${model_cfg.context_len}
  action_horizon: 0
  future_seq_len: ${model_cfg.context_len}
  min_future_sep: 1 
callbacks:
  epoch_end:
    - _target_: qfat.callbacks.train_callbacks.RolloutCallback
      is_goal_conditional: true
      env_cfg:
        _target_: qfat.environments.goal_conditional.GoalAppendingWrapper
        env:
          _target_: qfat.environments.kitchen.env.NormalizedKitchenWrapper
          start_from_data: false
          mask_goals: true  # whether to zero out the goals from the state
          complete_in_any_order: false
          terminate_on_task_complete: true
        dataset: ${training_dataset_cfg}
        future_seq_len: ${slicer_cfg.future_seq_len}
        min_future_sep: ${slicer_cfg.min_future_sep}
        only_sample_tail: ${slicer_cfg.only_sample_tail} 
        use_labels_env_task: true
      sampler_cfg:
        _target_: qfat.samplers.sampler.AutoRegressiveSampler
        context_len: # leave blank to use the model's context length
        temperature: 0.000001
        horizon: ${slicer_cfg.action_horizon}
        use_tensors: true
      frequency: ${n_save_model}
      n_rollouts: 50
      max_steps: 280
      log_entropy: false
      skip: 50
n_save_model: ${n_eval} 
n_eval: 20
device: "mps"
train_ratio: 0.95
reset_epoch: false
reset_cfg: false